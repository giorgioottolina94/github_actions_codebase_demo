{"cells":[{"cell_type":"markdown","metadata":{"id":"UUwYk1a0jCFY"},"source":["# Una Guida Introduttiva a CI/CD per il Machine Learning\n","\n","L'Integrazione Continua (CI) e il Deployment Continuo (CD) sono pratiche comunemente usate nello sviluppo software per automatizzare il processo di integrazione delle modifiche al codice, testarle e rilasciare rapidamente l'applicazione aggiornata. Inizialmente, queste pratiche sono state sviluppate per applicazioni software tradizionali, ma stanno diventando sempre più rilevanti anche nei progetti di machine learning (ML).\n","\n","In questa guida completa, daremo un'occhiata a CI/CD per ML e impareremo come costruire la nostra pipeline di machine learning che automatizzerà il processo di addestramento, valutazione e deployment del modello. Questa guida presenta un progetto semplice che utilizza solo GitHub Actions per automatizzare l'intero processo. La maggior parte delle cose che discuteremo sono ben note agli ingegneri di machine learning e ai data scientist. L'unica cosa che impareranno qui è come usare GitHub Actions, Makefile, CML e Hugging Face CLI."],"id":"UUwYk1a0jCFY"},{"cell_type":"markdown","metadata":{"id":"u_ml_RYAjCFa"},"source":["## Perché CI/CD per il Machine Learning?\n","CI/CD è una svolta quando si tratta di rendere operativo il tuo modello e usarlo per sviluppare un prodotto. Semplificare il processo di automazione fornisce una soluzione priva di bug, veloce e scalabile per il tuo progetto ML, permettendoti di concentrarti sul miglioramento del modello piuttosto che sulla gestione e il deployment della soluzione. In particolare, CI/CD per il machine learning aiuta con quanto segue:\n","\n","1.  **Automatizza la pipeline di addestramento**\n","    Con CI/CD, puoi riaddestrare automaticamente i tuoi modelli su nuovi dati a intervalli regolari, risparmiando tempo rispetto all'attivazione manuale del riaddestramento.\n","2.  **Individua precocemente gli errori**\n","    CI/CD aiuta a garantire che i modelli possano essere ricostruiti e riaddestrati esattamente allo stesso modo, consentendo la riproducibilità dei risultati. Ambienti, versionamento di modelli e dati, e configurazioni sono codificati.\n","3.  **Test e monitoraggio**\n","    CI/CD consente test automatizzati di nuovi modelli prima del deployment per verificare la presenza di problemi. Abilita anche un migliore monitoraggio dei modelli post-deployment attraverso l'integrazione con strumenti di monitoraggio.\n","4.  **Iterazione più rapida**\n","    Nuove versioni o esperimenti del modello possono essere rapidamente addestrati, testati e rilasciati in modo automatizzato con CI/CD. Accelera lo sviluppo e il miglioramento dei sistemi ML.\n","5.  **Scalabilità**\n","    Man mano che il progetto ML cresce in dimensioni e complessità, la gestione manuale dell'intero ciclo di vita diventa impraticabile. Le pipeline CI/CD forniscono una soluzione scalabile in grado di gestire grandi volumi di dati, numerosi modelli e diverse dipendenze mantenendo efficienza e affidabilità."],"id":"u_ml_RYAjCFa"},{"cell_type":"markdown","metadata":{"id":"sVjWwNFXjCFb"},"source":["## Descrizione del Progetto\n","In questa guida, sarai accompagnato attraverso il processo di configurazione di account e ambienti, creazione di una pipeline CI/CD e ottimizzazione dell'intero processo. Utilizzeremo pipeline scikit-learn per addestrare il nostro algoritmo random forest e costruire un classificatore di farmaci. Dopo l'addestramento, automatizzeremo il processo di valutazione usando CML. Infine, costruiremo e rilasceremo l'applicazione web su Hugging Face Hub. Dall'addestramento alla valutazione, l'intero processo sarà automatizzato usando GitHub Actions. Tutto quello che devi fare è inviare (push) il codice al tuo repository GitHub e, entro due minuti, il modello sarà aggiornato su Hugging Face con l'app, il modello e i risultati aggiornati."],"id":"sVjWwNFXjCFb"},{"cell_type":"markdown","metadata":{"id":"HPdO-vDVjCFb"},"source":["## Configurazione\n","In questa sezione, creeremo un repository GitHub, i file e le cartelle necessari, e uno Space su Hugging Face.\n","\n","Aggiungi il nome e la descrizione del repository, seleziona il file README e imposta .gitignore come Python.\n","\n","Dopo aver creato il repository, dobbiamo copiare il suo URL. Quindi, apri il terminale o la bash e naviga nella directory in cui vogliamo memorizzare la cartella del progetto.\n","Infine, clona il repository eseguendo il seguente comando:\n","```bash\n","git clone [https://github.com/....git)\n","```\n","\n","Per iniziare, usa il tuo IDE preferito per aprire il repository locale. Raccomandiamo di usare VSCode per questo progetto. Una volta avviato il tuo IDE, vedrai un workspace VSCode contenente file come README e LICENSE."],"id":"HPdO-vDVjCFb"},{"cell_type":"markdown","metadata":{"id":"sbAiUoT-jCFb"},"source":["### Hugging Face Spaces\n","Creiamo uno [Hugging Face Space](https://huggingface.co/spaces) che useremo per rilasciare la nostra applicazione con il file del modello.\n","1.  Clicca sulla tua immagine del profilo e seleziona \"New Space\".\n","2.  Aggiungi il nome dello Space, la Licenza, il tipo di SDK e clicca su Create Space.\n","3.  Per modificare il file README.md, clicca sui tre puntini in alto a sinistra, seleziona Files e apporta le modifiche necessarie.\n","4.  Copieremo i metadati dal file README dello Space e li incolleremo nel nostro file README locale che rimarrà nella cartella App."],"id":"sbAiUoT-jCFb"},{"cell_type":"markdown","metadata":{"id":"3-Qc2S99jCFc"},"source":["### File Essenziali\n","Dobbiamo creare la cartella e i file necessari prima di iniziare a sperimentare e costruire pipeline. Questo ci aiuterà nel lungo periodo a mantenere pulito lo spazio di lavoro.\n","\n","**Crea Cartelle**\n","1.  **App:** per aggiungere il file del classificatore dell'app web, il file README dell'app con i metadati e `requirements.txt` per installare i pacchetti necessari.\n","2.  **Data:** per tutti i nostri file CSV.\n","3.  **Model:** per i file del modello addestrato.\n","4.  **Results:** per salvare metriche e risultati in file PNG.\n","\n","**Cartella App**\n","Crea un file Python chiamato `drug_app.py`, insieme a un file `README.md` e un file `requirements.txt`, e sposta tutti questi file nella cartella App.\n","\n","Contenuto di `App/README.md` (per Hugging Face Spaces):\n","```yaml\n","title: Drug Classification\n","emoji:\n","colorFrom: blue\n","colorTo: purple\n","sdk: gradio\n","sdk_version: 4.10. # O la versione che stai usando\n","app_file: app.py # O drug_app.py se lo rinomini per lo Space\n","pinned: false\n","license: apache-2.0\n","```\n","\n","Modifica il file `requirements.txt` nella cartella `App` fornendo i pacchetti Python necessari per l'app Gradio:\n","Contenuto di `App/requirements.txt`:\n","```\n","gradio\n","scikit-learn\n","skops\n","pandas # Se usato direttamente nell'app per caricare/manipolare dati\n","```\n","Nota: i file requirement e README differiranno per il repository GitHub e lo Hugging Face Space. Il `requirements.txt` principale del repository conterrà pacchetti per l'addestramento e la CI, mentre quello nella cartella `App` è specifico per l'ambiente di esecuzione dell'app Gradio su Hugging Face.\n","\n","**Cartella Data**\n","Scarica il dataset [Drug Classification da Kaggle](https://www.kaggle.com/datasets/prathamtripathi/drug-classification), estrai il file CSV e spostalo nella cartella `Data`.\n","\n","**Cartelle Model e Results**\n","Entrambe le cartelle Model e Results rimarranno inizialmente vuote poiché saranno popolate dallo script Python che eseguiamo.\n","\n","**File del Repository (nella root)**\n","1.  Crea un `Makefile` per semplificare l'esecuzione dello script nel workflow di GitHub Action.\n","2.  Crea un Jupyter Notebook chiamato `notebook.ipynb` (questo stesso file!). In questo notebook, sperimenteremo i nostri algoritmi e le pipeline di elaborazione.\n","3.  Crea un file `requirements.txt` (nella root). Sarà usato per configurare l'ambiente durante l'esecuzione dei job del workflow CI (addestramento, formattazione, ecc.).\n","    Contenuto di `requirements.txt` (root del progetto):\n","    ```\n","    pandas\n","    scikit-learn\n","    matplotlib\n","    skops\n","    # Per CML e Makefile\n","    black # Per la formattazione\n","    # Aggiungere altre dipendenze specifiche per l'addestramento se necessario\n","    ```\n","4.  Crea un file chiamato `train.py`. Conterrà codice Python per caricare ed elaborare i dati, nonché per addestrare, valutare e salvare il modello e le metriche di performance.\n","\n","Ecco come dovrebbe apparire la struttura della tua directory principale del progetto:"],"id":"3-Qc2S99jCFc"},{"cell_type":"markdown","metadata":{"id":"hs8t3yzrjCFc"},"source":["```\n","CICD-for-Machine-Learning/            # Root del progetto\n","├── App/                              # File specifici per l'app Gradio\n","│   ├── drug_app.py                   # Script dell'app Gradio\n","│   ├── README.md                     # README per Hugging Face Space\n","│   └── requirements.txt              # Dipendenze per l'app Gradio\n","├── Data/                             # Dati grezzi\n","│   └── drug.csv\n","├── Model/                            # Modelli addestrati salvati\n","│   └── drug_pipeline.skops           # (Verrà creato da train.py)\n","├── Results/                          # Risultati della valutazione\n","│   ├── metrics.txt                   # (Verrà creato da train.py)\n","│   └── model_results.png             # (Verrà creato da train.py)\n","├── .github/                          # Workflow di GitHub Actions\n","│   └── workflows/\n","│       ├── ci.yml\n","│       └── cd.yml\n","├── .gitignore                        # File ignorati da Git\n","├── LICENSE                           # Licenza del progetto\n","├── Makefile                          # Comandi automatizzati\n","├── notebook.ipynb                    # Questo Jupyter Notebook\n","├── README.md                         # README principale del progetto\n","├── requirements.txt                  # Dipendenze per addestramento e CI\n","└── train.py                          # Script di addestramento del modello\n","```"],"id":"hs8t3yzrjCFc"},{"cell_type":"markdown","metadata":{"id":"-8TtNx5njCFc"},"source":["## Addestramento e Valutazione del Modello di Classificazione dei Farmaci\n","In questa parte, sperimenteremo la creazione di codice Python che elabora i dati e addestra un modello usando una pipeline scikit-learn. Quindi lo valuteremo e salveremo i risultati e il modello.\n","\n","### Caricamento del Dataset\n","Useremo pandas per caricare il nostro file CSV, mescolarlo usando la funzione `sample` e visualizzare le prime tre righe."],"id":"-8TtNx5njCFc"},{"cell_type":"code","execution_count":null,"metadata":{"id":"G2MZl7vhjCFd"},"outputs":[],"source":["import pandas as pd\n","\n","# Assumendo che drug.csv sia in una sottocartella 'Data'\n","drug_df = pd.read_csv(\"Data/drug.csv\")\n","# Aggiunto random_state per riproducibilità\n","drug_df = drug_df.sample(frac=1, random_state=42)\n","print(\"Prime tre righe del dataset mescolato:\")\n","print(drug_df.head(3))"],"id":"G2MZl7vhjCFd"},{"cell_type":"markdown","metadata":{"id":"q_J-Ka6ujCFe"},"source":["### Divisione Train Test\n","Crea una variabile dipendente e una variabile indipendente. Quindi dividile in set di addestramento e di test. Questo ti aiuterà a valutare le prestazioni del tuo modello."],"id":"q_J-Ka6ujCFe"},{"cell_type":"code","execution_count":null,"metadata":{"id":"RUVY8QpNjCFe"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X = drug_df.drop(\"Drug\", axis=1) # Manteniamo DataFrame per nomi colonne\n","y = drug_df.Drug.values\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.3, random_state=125, stratify=y # Aggiunto stratify per mantenere proporzioni classi\n",")\n","print(f\"Dimensioni X_train: {X_train.shape}\")\n","print(f\"Dimensioni X_test: {X_test.shape}\")"],"id":"RUVY8QpNjCFe"},{"cell_type":"markdown","metadata":{"id":"PPnOzswUjCFe"},"source":["### Creazione della Pipeline di Preprocessing e Addestramento\n","Costruiremo una pipeline di elaborazione usando `ColumnTransformer`, che convertirà i valori categorici in numeri, riempirà i valori mancanti e scalerà le colonne numeriche. Successivamente, creeremo una pipeline di addestramento che prenderà i dati trasformati e addestrerà un classificatore random forest. Infine, addestreremo il modello.\n","Usando le pipeline, possiamo garantire riproducibilità, modularità e chiarezza nel nostro codice."],"id":"PPnOzswUjCFe"},{"cell_type":"code","execution_count":null,"metadata":{"id":"p_UVjXpkjCFe"},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.impute import SimpleImputer\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import OrdinalEncoder, StandardScaler, OneHotEncoder\n","\n","# Identificazione delle colonne categoriche e numeriche dai nomi\n","categorical_features = ['Sex', 'BP', 'Cholesterol']\n","numerical_features = ['Age', 'Na_to_K']\n","\n","# Creazione dei trasformatori per le feature numeriche e categoriche\n","numerical_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='median')),\n","    ('scaler', StandardScaler())])\n","\n","categorical_transformer = Pipeline(steps=[\n","    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n","    # Nota: OrdinalEncoder potrebbe essere usato se c'è un ordinamento intrinseco,\n","    # ma OneHotEncoder è generalmente più sicuro per variabili nominali in RandomForest.\n","])\n","\n","# Creazione del ColumnTransformer\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numerical_transformer, numerical_features),\n","        ('cat', categorical_transformer, categorical_features)\n","    ])\n","\n","# Creazione della pipeline finale con preprocessing e modello\n","model_pipeline = Pipeline(\n","    steps=[\n","        (\"preprocessor\", preprocessor),\n","        (\"classifier\", RandomForestClassifier(n_estimators=100, random_state=125, class_weight='balanced')) # Aggiunto class_weight\n","    ]\n",")\n","\n","# Addestramento della pipeline\n","model_pipeline.fit(X_train, y_train)\n","print(\"Pipeline di addestramento completata.\")"],"id":"p_UVjXpkjCFe"},{"cell_type":"markdown","metadata":{"id":"JHCW74GzjCFe"},"source":["### Valutazione del Modello\n","Valuta le prestazioni del modello calcolando sia l'accuratezza che il punteggio F1."],"id":"JHCW74GzjCFe"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5LctyQaAjCFe"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, f1_score, classification_report\n","\n","predictions = model_pipeline.predict(X_test)\n","accuracy = accuracy_score(y_test, predictions)\n","f1 = f1_score(y_test, predictions, average=\"macro\") # 'macro' per F1 non pesato tra classi\n","\n","print(f\"Accuratezza: {accuracy*100:.2f}%\")\n","print(f\"Punteggio F1 (Macro): {f1:.2f}\")\n","print(\"\\nReport di Classificazione Dettagliato:\")\n","print(classification_report(y_test, predictions))"],"id":"5LctyQaAjCFe"},{"cell_type":"markdown","metadata":{"id":"_DqMlu3njCFf"},"source":["Il nostro modello ha funzionato bene."],"id":"_DqMlu3njCFf"},{"cell_type":"markdown","metadata":{"id":"QokB7VmMjCFf"},"source":["### Salvataggio delle Metriche e della Matrice di Confusione\n","Salviamo le metriche in un file di testo e generiamo e salviamo la matrice di confusione."],"id":"QokB7VmMjCFf"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3PVkiuCxjCFf"},"outputs":[],"source":["import os\n","if not os.path.exists(\"Results\"):\n","    os.makedirs(\"Results\")\n","\n","with open(\"Results/metrics.txt\", \"w\") as outfile:\n","    outfile.write(f\"Accuratezza: {accuracy:.2f}\\n\")\n","    outfile.write(f\"Punteggio F1 (Macro): {f1:.2f}\\n\\n\")\n","    outfile.write(\"Report di Classificazione Dettagliato:\\n\")\n","    outfile.write(classification_report(y_test, predictions))\n","print(\"Metriche salvate in Results/metrics.txt\")"],"id":"3PVkiuCxjCFf"},{"cell_type":"code","execution_count":null,"metadata":{"id":"U63NDxCZjCFf"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n","\n","cm = confusion_matrix(y_test, predictions, labels=model_pipeline.classes_)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model_pipeline.classes_)\n","fig, ax = plt.subplots(figsize=(8, 6))\n","disp.plot(ax=ax, cmap=plt.cm.Blues)\n","plt.title(\"Matrice di Confusione\")\n","plt.xticks(rotation=45)\n","plt.tight_layout()\n","plt.savefig(\"Results/model_results.png\", dpi=120)\n","plt.show()\n","print(\"Matrice di confusione salvata in Results/model_results.png\")"],"id":"U63NDxCZjCFf"},{"cell_type":"markdown","metadata":{"id":"sQKKD16cjCFf"},"source":["### Salvataggio del Modello Addestrato\n","Ora salveremo la nostra pipeline completa (preprocessing + modello) usando il pacchetto Python `skops`. Questo ci aiuterà a salvare l'intera pipeline in un formato che può essere facilmente caricato per le predizioni."],"id":"sQKKD16cjCFf"},{"cell_type":"code","execution_count":null,"metadata":{"id":"uQf7QU08jCFf"},"outputs":[],"source":["import skops.io as sio\n","import os\n","\n","if not os.path.exists(\"Model\"):\n","    os.makedirs(\"Model\")\n","\n","# Il file .skops è un archivio zip, assicurati che il nome del file sia corretto.\n","sio.dump(model_pipeline, \"Model/drug_pipeline.skops\")\n","print(\"Pipeline del modello salvata in Model/drug_pipeline.skops\")"],"id":"uQf7QU08jCFf"},{"cell_type":"markdown","metadata":{"id":"g6JIY8snjCFf"},"source":["Puoi semplicemente caricare l'intera pipeline, e funzionerà immediatamente senza ri-eseguire il preprocessing dei tuoi dati o apportare modifiche al codice."],"id":"g6JIY8snjCFf"},{"cell_type":"code","execution_count":null,"metadata":{"id":"e_QlX4zwjCFf"},"outputs":[],"source":["loaded_pipe = sio.load(\"Model/drug_pipeline.skops\", trusted=True)\n","print(\"Pipeline caricata con successo.\")\n","# Puoi fare una predizione di prova per verificare\n","try:\n","    sample_prediction = loaded_pipe.predict(X_test.iloc[:1]) # Usa iloc per DataFrame\n","    print(f\"Predizione di prova su un campione: {sample_prediction}\")\n","except Exception as e:\n","    print(f\"Errore durante la predizione di prova: {e}\")"],"id":"e_QlX4zwjCFf"},{"cell_type":"markdown","metadata":{"id":"GM-mJCWIjCFf"},"source":["### Creazione dello script `train.py`\n","Copia e incolla l'intero codice (da Caricamento del Dataset a Salvataggio del Modello) nel file `train.py`. Questo sarà lo script di addestramento standardizzato che verrà eseguito nel workflow CI ogni volta che c'è una modifica nei dati o nel codice.\n","\n","(Puoi usare la magia `%%writefile train.py` in una cella di codice per creare questo file direttamente dal notebook, includendo tutte le celle di codice rilevanti da sopra)."],"id":"GM-mJCWIjCFf"},{"cell_type":"markdown","metadata":{"id":"u2YCLlt3jCFf"},"source":["## Passaggi per Costruire la Tua Pipeline di Integrazione Continua\n","In questa sezione, tratteremo CML, Makefile e la configurazione dei workflow di GitHub Action per automatizzare l'addestramento, la valutazione e il versionamento del nostro progetto.\n","\n","### CI Pipeline\n","\n","#### CML (Continuous Machine Learning)\n","Continuous Machine Learning (CML) è una libreria open-source che ti permette di implementare l'integrazione continua nei tuoi progetti di machine learning. Useremo la GitHub Action \"iterative/setup-cml\" che utilizza funzioni CML nel workflow per automatizzare la generazione del report di valutazione del modello. Cosa significa? Ogni volta che invii (push) modifiche a GitHub, genererà un report sotto il commit e ti invierà un'email con le metriche di performance e una matrice di confusione.\n","\n","#### Makefile\n","Un `Makefile` è un file che consiste in un insieme di istruzioni usate dal comando `make` per automatizzare vari task, come compilare codice, eseguire test, configurare ambienti, preprocessare dati, addestrare e valutare modelli, e rilasciare modelli. Possiamo usare i comandi `make` per eseguire script multipli per rendere il file del workflow CI pulito e semplice. Il `Makefile` contiene il nome dell'insieme di comandi e lo script per eseguire quei comandi.\n","Ecco il nostro `Makefile`:"],"id":"u2YCLlt3jCFf"},{"cell_type":"code","execution_count":null,"metadata":{"id":"hbLbyXrsjCFg"},"outputs":[],"source":["%%writefile Makefile\n","# Installa le dipendenze per l'addestramento e gli strumenti CI\n","install:\n","\tpip install --upgrade pip\n","\tpip install -r requirements.txt # Questo usa il requirements.txt della root\n","\n","# Formatta il codice Python usando Black\n","format:\n","\tblack *.py App/*.py # Formatta i file .py nella root e nella cartella App\n","\n","# Esegue lo script di addestramento del modello\n","train:\n","\tpython train.py\n","\n","# Genera un report di valutazione usando CML\n","eval:\n","\techo \"## Metriche del Modello\" > report.md\n","\t# Assicurati che il percorso a metrics.txt sia corretto\n","\tcat Results/metrics.txt >> report.md\n","\techo \"\\n\\n## Grafico Matrice di Confusione\" >> report.md\n","\t# Assicurati che il percorso a model_results.png sia corretto\n","\techo \"![Matrice di Confusione](./Results/model_results.png)\" >> report.md\n","\tcml comment create report.md\n","\n","# Aggiungi altre regole se necessario, per esempio per pulire i file generati:\n","clean:\n","\trm -rf Model/* Results/* report.md __pycache__/ *.pyc App/__pycache__/ App/*.pyc\n","\t# Aggiungi altre pulizie se necessario"],"id":"hbLbyXrsjCFg"},{"cell_type":"markdown","metadata":{"id":"ujSl1JILjCFg"},"source":["Abbiamo comandi per installare pacchetti Python (`install`), formattare codice (`format`), eseguire script di addestramento (`train`), e generare report CML (`eval`).\n","\n","Dopo aver preparato questi file, aggiungeremo le modifiche, creeremo un commit e invieremo (push) le modifiche al server remoto di GitHub.\n","```bash\n","git add .\n","git commit -m \"Configurazione iniziale del progetto CI/CD per ML\"\n","git push origin main\n","```\n"],"id":"ujSl1JILjCFg"},{"cell_type":"markdown","metadata":{"id":"VCNYIjSvjCFg"},"source":["### GitHub Actions\n","Per automatizzare l'addestramento e la valutazione, dobbiamo creare un workflow di GitHub Action. Per fare ciò, crea una cartella `.github/workflows/` nel tuo repository e aggiungi un file YAML (es. `ci.yml`).\n","\n","Ecco un esempio del contenuto del file `.github/workflows/ci.yml`:\n","1.  Aggiungi il nome del workflow.\n","2.  Imposta il trigger in modo che il workflow venga eseguito su un push o pull request al branch main o un'esecuzione manuale.\n","3.  Definisci i job. Configureremo un job `build` che verrà eseguito su un server Linux (ubuntu-latest).\n","4.  Definisci gli step all'interno del job: checkout del codice, setup di Python, installazione delle dipendenze, formattazione, addestramento e valutazione.\n","5.  Per il CML, è necessario impostare i permessi e fornire un token (GitHub Actions lo fornisce automaticamente come `secrets.GITHUB_TOKEN`)."],"id":"VCNYIjSvjCFg"},{"cell_type":"code","execution_count":null,"metadata":{"id":"CmzRfR6IjCFg"},"outputs":[],"source":["%%writefile .github/workflows/ci.yml\n","name: Integrazione Continua Modello ML\n","\n","on:\n","  push:\n","    branches: [ \"main\", \"develop\" ] # Esegui su push a main o develop\n","  pull_request:\n","    branches: [ \"main\" ] # Esegui su pull request verso main\n","  workflow_dispatch: # Permette l'esecuzione manuale\n","\n","permissions:\n","  contents: write # Necessario per CML per creare commenti/report\n","  pull-requests: write # Necessario per CML per commentare su PR\n","\n","jobs:\n","  train_evaluate:\n","    runs-on: ubuntu-latest\n","    steps:\n","      - name: Checkout del codice\n","        uses: actions/checkout@v4\n","\n","      - name: Setup Python\n","        uses: actions/setup-python@v5\n","        with:\n","          python-version: '3.9' # Specifica la tua versione di Python\n","\n","      - name: Installa dipendenze\n","        run: make install\n","        # Alternativamente, se vuoi più controllo o caching:\n","        # run: |\n","        #   pip install --upgrade pip\n","        #   pip install -r requirements.txt\n","\n","      - name: Formatta codice (linting)\n","        run: make format\n","        # Opzionale: fallisci il workflow se la formattazione cambia file\n","        # run: |\n","        #   make format\n","        #   git diff --exit-code --quiet || (echo \"Il codice non è formattato correttamente. Esegui 'make format' localmente.\" && exit 1)\n","\n","      - name: Addestra modello\n","        run: make train\n","\n","      - name: Valuta modello e crea report CML\n","        uses: iterative/setup-cml@v2 # Setup CML\n","        # env:\n","          # REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }} # GITHUB_TOKEN è di solito sufficiente\n","          # CML usa GITHUB_TOKEN per default se REPO_TOKEN non è esplicitamente impostato\n","      - run: make eval\n","        env:\n","          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n","\n","      # (Opzionale) Step per salvare artefatti come il modello addestrato o i risultati\n","      - name: Carica artefatti dei Risultati\n","        uses: actions/upload-artifact@v4\n","        with:\n","          name: model-results\n","          path: |\n","            Results/\n","            Model/\n","            report.md"],"id":"CmzRfR6IjCFg"},{"cell_type":"markdown","metadata":{"id":"yFjmp31MjCFg"},"source":["Una volta che questo file è nel tuo repository, GitHub Actions lo rileverà ed eseguirà il workflow secondo i trigger definiti.\n","\n","Potresti incontrare fallimenti mentre scopri errori e sintassi, motivo per cui è importante leggere la [Sintassi del workflow per GitHub Actions](https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions) prima di immergerti nelle GitHub Action.\n","\n","### Salvataggio dei Risultati in un Nuovo Branch (Opzionale, per Versionamento)\n","Stiamo generando il report di valutazione. Se vuoi versionare il modello e i risultati direttamente nel repository Git (alternativa a DVC o altri strumenti di versionamento di modelli/dati), puoi creare un nuovo branch (es. \"update\" o \"gh-pages\" per i report) e fare il push del modello aggiornato, dei risultati e del report lì.\n","\n","**Aggiorna Makefile (aggiungi questo target per il versionamento dei risultati):**"],"id":"yFjmp31MjCFg"},{"cell_type":"code","execution_count":null,"metadata":{"id":"izf_OeeNjCFh"},"outputs":[],"source":["%%writefile -a Makefile\n","\n","# Configura git, committa e fa il push del modello, risultati e report al branch 'update'\n","update-results-branch:\n","\t# Configura l'utente git per questo workflow specifico (usa il bot di GitHub Actions)\n","\tgit config --global user.name 'github-actions[bot]'\n","\tgit config --global user.email 'github-actions[bot]@users.noreply.github.com'\n","\t# Controlla se il branch 'update' esiste, altrimenti crealo\n","\tgit checkout update || git checkout -b update\n","\t# Assicurati di essere aggiornato con la history remota, se necessario, o forza il push\n","\t# git pull origin update # Opzionale, dipende dalla strategia\n","\t# Aggiungi i file generati. Assicurati che questi file siano presenti e aggiornati.\n","\tgit add Model/drug_pipeline.skops Results/metrics.txt Results/model_results.png report.md\n","\t# Committa solo se ci sono modifiche\n","\tgit commit -m \"Aggiorna modello, risultati e report dall'esecuzione CI [skip ci]\" || echo \"Nessuna modifica da committare\"\n","\t# Fai il push al branch 'update'. L'opzione --force può essere pericolosa; usala con cautela.\n","\tgit push origin update"],"id":"izf_OeeNjCFh"},{"cell_type":"markdown","metadata":{"id":"CK58n34_jCFh"},"source":["**Aggiorna `ci.yml` (aggiungi questo step al job `train_evaluate` se vuoi fare il push dei risultati):**\n","\n","```yaml\n","# (All'interno degli steps del job train_evaluate in ci.yml, dopo 'make eval')\n","      - name: Pubblica risultati sul branch 'update'\n","        if: github.ref == 'refs/heads/main' # Esegui solo se il workflow è su main\n","        run: make update-results-branch\n","        # Potrebbe essere necessario fornire un token con permessi di scrittura se GITHUB_TOKEN predefinito non è sufficiente\n","        # env:\n","        #   GH_TOKEN: ${{ secrets.PERSONAL_ACCESS_TOKEN_WITH_WRITE_ACCESS }} # Se necessario\n","```\n","**Nota:** Per fare il push a un branch protetto o se si usano token specifici, potrebbe essere necessario configurare i secrets di GitHub (es. `GH_TOKEN`) e passarli allo script. Per il push da parte di `github-actions[bot]`, i permessi `contents: write` sul workflow dovrebbero essere sufficienti per i branch non protetti.\n","\n","Una volta aggiornati i file e inviate (push) le modifiche al branch main, potrai vedere la magia accadere in tempo reale. Verrà generato un report analitico, insieme a un modello aggiornato che potrà essere rilasciato su Hugging Face nella parte di deployment continuo."],"id":"CK58n34_jCFh"},{"cell_type":"markdown","metadata":{"id":"XuHFuJ_vjCFh"},"source":["## Passaggi per Costruire la Tua Pipeline di Deployment Continuo (CD)\n","Nella sezione Deployment Continuo, scopriremo come automatizzare il processo di rilascio sia del modello che dell'applicazione. Ciò comporta il recupero (pull) del modello aggiornato e del file dell'applicazione (ad esempio, dal branch `update` se lo stai usando per versionare), l'accesso alla CLI di Hugging Face usando un token, l'invio (push) dei file del modello e dell'applicazione, e infine il rilascio dell'applicazione su Hugging Face Spaces."],"id":"XuHFuJ_vjCFh"},{"cell_type":"markdown","metadata":{"id":"iU8P6DSgjCFh"},"source":["### Costruzione dell'App Gradio\n","Per rilasciare il nostro modello e accedervi, dobbiamo creare un'app Gradio. Il codice per questa app sarà in `App/drug_app.py`. Questa app includerà:\n","1.  Caricamento della pipeline scikit-learn (modello) salvata da `skops`.\n","2.  Una funzione Python per predire le etichette dei farmaci in base all'input dell'utente.\n","3.  Creazione di un'interfaccia utente di input usando slider Gradio per valori float e radio Gradio per valori categorici.\n","4.  Creazione di input di esempio per testare facilmente il modello.\n","5.  Fornire il titolo dell'applicazione, una breve descrizione delle sue caratteristiche e funzionalità, e un piè di pagina che includa qualsiasi informazione rilevante.\n","6.  Forniremo tutte queste variabili e la funzione di predizione alla funzione `gr.Interface()` di Gradio e la avvieremo.\n","7.  Per rendere la nostra app web moderna, useremo un tema (`gr.themes.Soft()`).\n","\n","Assicurati che il file `App/drug_app.py` contenga il codice Gradio finale. Ecco un riepilogo del codice che dovrebbe essere lì:"],"id":"iU8P6DSgjCFh"},{"cell_type":"code","execution_count":null,"metadata":{"id":"lGMNLmPjjCFh"},"outputs":[],"source":["%%writefile App/drug_app.py\n","import gradio as gr\n","import skops.io as sio\n","import os\n","import pandas as pd # Aggiunto per creare DataFrame di esempio\n","\n","# Determina il percorso del modello.\n","# Quando eseguito su Hugging Face Spaces, il modello sarà probabilmente nella directory 'Model' relativa alla root dello Space.\n","model_file_name = 'drug_pipeline.skops'\n","model_path_in_space = f\"./Model/{model_file_name}\" # Percorso comune su HF Spaces se 'Model' è una cartella caricata\n","model_path_local = f\"../Model/{model_file_name}\" # Per test locali se App è sorella di Model\n","\n","loaded_model = None\n","try:\n","    # Prova a caricare dal percorso dello Space prima\n","    if os.path.exists(model_path_in_space):\n","        loaded_model = sio.load(model_path_in_space, trusted=True)\n","    elif os.path.exists(model_path_local):\n","        loaded_model = sio.load(model_path_local, trusted=True)\n","    else:\n","        print(f\"ERRORE: File modello '{model_file_name}' non trovato nei percorsi attesi.\")\n","except Exception as e:\n","    print(f\"ERRORE durante il caricamento del modello: {e}\")\n","\n","def predict_drug(age, sex, blood_pressure, cholesterol, na_to_k_ratio):\n","    if loaded_model is None:\n","        return \"ERRORE: Modello non caricato correttamente. Controllare i log dello Space.\"\n","    try:\n","        # Crea un DataFrame per la predizione, con i nomi delle colonne come durante l'addestramento\n","        feature_names = ['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K']\n","        input_data = pd.DataFrame([[age, sex, blood_pressure, cholesterol, na_to_k_ratio]], columns=feature_names)\n","\n","        # Conversione dei tipi se necessario, es. Age e Na_to_K a numerico\n","        input_data['Age'] = pd.to_numeric(input_data['Age'])\n","        input_data['Na_to_K'] = pd.to_numeric(input_data['Na_to_K'])\n","\n","        predicted_drug = loaded_model.predict(input_data)[0]\n","        label = f\"Farmaco Predetto: {predicted_drug}\"\n","    except Exception as e:\n","        print(f\"Errore durante la predizione: {e}\")\n","        label = f\"Errore nella predizione: Controlla i tipi di input o i log. ({e})\"\n","    return label\n","\n","inputs_ui = [\n","    gr.Slider(minimum=15, maximum=74, step=1, value=47, label=\"Età (anni)\"),\n","    gr.Radio([\"M\", \"F\"], value=\"F\", label=\"Sesso\"),\n","    gr.Radio([\"HIGH\", \"LOW\", \"NORMAL\"], value=\"LOW\", label=\"Pressione Sanguigna (BP)\"),\n","    gr.Radio([\"HIGH\", \"NORMAL\"], value=\"HIGH\", label=\"Colesterolo\"),\n","    gr.Slider(minimum=6.0, maximum=38.0, step=0.1, value=13.935, label=\"Rapporto Na/K (Sodio/Potassio)\")\n","]\n","outputs_ui = gr.Label(label=\"Risultato Predizione\")\n","\n","examples_ui = [\n","    [47, \"F\", \"LOW\", \"HIGH\", 13.935], # DrugY\n","    [30, \"M\", \"HIGH\", \"NORMAL\", 15.4], # DrugY\n","    [35, \"F\", \"LOW\", \"NORMAL\", 8.0],   # drugX\n","    [50, \"M\", \"HIGH\", \"HIGH\", 34.0],  # DrugY\n","    [22, \"F\", \"NORMAL\", \"NORMAL\", 12.5],# drugX\n","    [68, \"M\", \"LOW\", \"HIGH\", 25.3],  # DrugY\n","    [16, \"F\", \"HIGH\", \"NORMAL\", 12.000],# drugC\n","    [61, \"M\", \"LOW\", \"HIGH\", 30.560] # DrugB\n","]\n","\n","title_app = \"💊 Classificatore di Farmaci\"\n","description_app = \"Inserisci i dettagli del paziente per predire il tipo di farmaco appropriato usando un modello di machine learning. Questa è una demo basata sul dataset 'Drug Classification' da Kaggle.\"\n","article_app = \"<p style='text-align: center;'>Sviluppato seguendo la guida 'A Beginner's Guide to CI/CD for Machine Learning'. <br> Modello: RandomForest addestrato con Scikit-learn e Skops. <br> Interfaccia: Gradio. Orchestrazione: GitHub Actions per CI/CD.</p>\"\n","\n","interface = gr.Interface(\n","    fn=predict_drug,\n","    inputs=inputs_ui,\n","    outputs=outputs_ui,\n","    examples=examples_ui,\n","    title=title_app,\n","    description=description_app,\n","    article=article_app,\n","    theme=gr.themes.Soft(primary_hue=gr.themes.colors.blue, secondary_hue=gr.themes.colors.purple),\n","    allow_flagging='never',\n","    live=False # Metti True per predizioni live mentre si cambiano gli input (può essere intensivo)\n",")\n","\n","# Per lanciare l'app quando eseguita direttamente (es. per test locali)\n","if __name__ == \"__main__\":\n"," print(\"Avvio dell'app Gradio localmente...\")\n"," interface.launch() # share=True per creare un link pubblico temporaneo da locale"],"id":"lGMNLmPjjCFh"},{"cell_type":"markdown","metadata":{"id":"6UzqdvFWjCFh"},"source":["Apri il terminale nella cartella `App` ed esegui l'app localmente per testarla:\n","```bash\n","python drug_app.py\n","```\n","Dovrebbe avviarsi su un URL locale come `http://127.0.0.1:7860`.\n"],"id":"6UzqdvFWjCFh"},{"cell_type":"markdown","metadata":{"id":"KppdFE97jCFh"},"source":["### Configurazione del Token Hugging Face per il Deployment\n","Per il deployment automatico su Hugging Face Spaces, avrai bisogno di un token di accesso Hugging Face.\n","1.  Vai al tuo profilo Hugging Face > Settings > Access Tokens.\n","2.  Crea un nuovo token. Dagli un nome (es. `GITHUB_ACTIONS_DEPLOY`) e un ruolo `write` (per permettere la scrittura nello Space).\n","3.  Copia il token generato.\n","4.  Nel tuo repository GitHub, vai su Settings > Secrets and variables > Actions.\n","5.  Clicca su \"New repository secret\". Nomina il secret `HF_TOKEN` (o il nome che preferisci, ma dovrà corrispondere a quello usato nel workflow) e incolla il token come valore."],"id":"KppdFE97jCFh"},{"cell_type":"markdown","metadata":{"id":"pWOmgNfijCFh"},"source":["### Workflow di Deployment Continuo (CD)\n","Creeremo un altro file di workflow GitHub, `.github/workflows/cd.yml`, per gestire il deployment su Hugging Face Spaces. Questo workflow verrà attivato dal completamento successful del workflow CI.\n","\n","**Aggiorna `Makefile` (aggiungi questi target per il deployment):**"],"id":"pWOmgNfijCFh"},{"cell_type":"code","execution_count":null,"metadata":{"id":"bglsfQPLjCFh"},"outputs":[],"source":["%%writefile -a Makefile\n","\n","# Login a Hugging Face CLI usando il token\n","hf-login:\n","\t# Assicurati che huggingface_hub sia installato\n","\tpip install -U huggingface_hub huggingface_hub[cli]\n","\thuggingface-cli login --token $(HF_TOKEN_SECRET) --add-to-git-credential\n","\n","# Carica i file necessari allo Hugging Face Space\n","# HF_SPACE_ID è nel formato 'username/spacename', es. 'kingabzpro/Drug-Classification'\n","hf-upload-space:\n","\t# Carica il contenuto della cartella App nella root dello Space\n","\t# huggingface-cli upload $(HF_SPACE_ID) App/ --repo-type=space --path-in-repo=. --commit-message=\"Deploy app files [skip ci]\"\n","\t# Carica la cartella Model (contenente drug_pipeline.skops) in una cartella 'Model' nello Space\n","\t# huggingface-cli upload $(HF_SPACE_ID) Model/ --repo-type=space --path-in-repo=Model --commit-message=\"Deploy model files [skip ci]\"\n","\t# Carica la cartella Results (opzionale, se vuoi mostrare i risultati nello Space files)\n","\t# huggingface-cli upload $(HF_SPACE_ID) Results/ --repo-type=space --path-in-repo=Results --commit-message=\"Deploy results files [skip ci]\"\n","\n","\t# Approccio più semplice: crea una cartella di staging e carica tutto in una volta\n","\tmkdir -p deploy_staging/Model deploy_staging/Results\n","\tcp App/* deploy_staging/ # Copia i file dell'app (drug_app.py, README.md, requirements.txt da App/)\n","\tcp Model/drug_pipeline.skops deploy_staging/Model/ # Copia il modello addestrato\n","\t# Opzionale: copia i risultati se vuoi che siano nello Space\n","\t# cp Results/* deploy_staging/Results/\n","\t# Carica il contenuto di deploy_staging nella root dello Space (o in sottocartelle specifiche)\n","\thuggingface-cli upload $(HF_SPACE_ID) deploy_staging/ --repo-type=space --path-in-repo=. --commit-message=\"Deploy app and model [skip ci]\"\n","\trm -rf deploy_staging # Pulisci\n","\n","# Target principale per il deployment\n","deploy-hf-space: hf-login hf-upload-space\n"],"id":"bglsfQPLjCFh"},{"cell_type":"markdown","metadata":{"id":"lLy04zryjCFo"},"source":["**Crea `.github/workflows/cd.yml`:**"],"id":"lLy04zryjCFo"},{"cell_type":"code","execution_count":null,"metadata":{"id":"YRUD2zMHjCFo"},"outputs":[],"source":["%%writefile .github/workflows/cd.yml\n","name: Deployment Continuo su Hugging Face\n","\n","on:\n","  workflow_run:\n","    workflows: [\"Integrazione Continua Modello ML\"] # Nome del workflow CI\n","    types:\n","      - completed # Attiva quando il workflow CI è completato\n","\n","jobs:\n","  deploy_to_hf_space:\n","    runs-on: ubuntu-latest\n","    # Esegui solo se il workflow CI (triggerante) ha avuto successo E se il trigger era su main o develop\n","    if: github.event.workflow_run.conclusion == 'success' && (github.event.workflow_run.head_branch == 'main' || github.event.workflow_run.head_branch == 'develop')\n","\n","    steps:\n","      - name: Checkout del codice dal branch del workflow CI\n","        uses: actions/checkout@v4\n","        with:\n","          # Fa il checkout del commit specifico che ha attivato il workflow CI\n","          ref: ${{ github.event.workflow_run.head_sha }}\n","          # Se hai fatto il push dei risultati in un branch 'update' nella CI, potresti voler fare il checkout di quel branch:\n","          # ref: 'update' # Assicurati che il branch esista\n","          fetch-depth: 0 # Necessario se devi fare switch di branch o interagire con la history di git\n","\n","      - name: Setup Python\n","        uses: actions/setup-python@v5\n","        with:\n","          python-version: '3.9' # Usa la stessa versione della CI\n","\n","      - name: Scarica artefatti (se il modello/risultati sono stati caricati dalla CI)\n","        # Questo step è necessario se il workflow CI carica artefatti invece di fare commit/push a un branch\n","        # Se hai fatto il commit dei file necessari (Modello, App, ecc.) nel repo, questo step non è necessario\n","        # e il checkout è sufficiente.\n","        # uses: actions/download-artifact@v4\n","        # with:\n","        #   name: model-results # Nome dell'artefatto dalla CI\n","        #   path: . # Scarica nella root del checkout\n","\n","      # Assicurati che i file necessari per il deployment (App/, Model/) siano presenti dopo il checkout o download\n","      - name: Verifica file necessari per il deployment\n","        run: |\n","          ls -R App/\n","          ls -R Model/\n","\n","      - name: Esegui Deployment su Hugging Face Space\n","        env:\n","          HF_TOKEN_SECRET: ${{ secrets.HF_TOKEN }} # Secret del repository GitHub\n","          HF_SPACE_ID: \"tuoUsernameHF/tuoNomeSpaceHF\" # Esempio: \"kingabzpro/Drug-Classification\"\n","        run: make deploy-hf-space\n"],"id":"YRUD2zMHjCFo"},{"cell_type":"markdown","metadata":{"id":"nK6yzuXwjCFo"},"source":["**Importante:** Sostituisci `\"tuoUsernameHF/tuoNomeSpaceHF\"` nel file `cd.yml` con il tuo effettivo ID dello Space Hugging Face (es. `\"kingabzpro/Drug-Classification\"`).\n","\n","Quando invii (push) le modifiche al branch `main` (o `develop`), il workflow CI (`ci.yml`) verrà eseguito. Se ha successo, attiverà il workflow CD (`cd.yml`), che quindi rilascerà la tua app e il modello aggiornati allo Hugging Face Space specificato."],"id":"nK6yzuXwjCFo"},{"cell_type":"markdown","metadata":{"id":"dRGTig8ljCFo"},"source":["### Riepilogo del Funzionamento dell'App su Hugging Face Spaces\n","Dopo che il workflow CD carica i file, Hugging Face Spaces:\n","1.  Rileva i file caricati (in particolare, cerca un `README.md` con metadati SDK o un file `app.py` e `requirements.txt` se l'SDK è specificato).\n","2.  Installa le dipendenze da `App/requirements.txt`.\n","3.  Esegue lo script specificato (es. `App/drug_app.py`).\n","L'app Gradio diventerà quindi accessibile all'URL del tuo Space."],"id":"dRGTig8ljCFo"},{"cell_type":"markdown","metadata":{"id":"rV5KSudhjCFo"},"source":["## Conclusione\n","Questa guida illustra come abbiamo automatizzato i processi di addestramento, valutazione, versionamento (opzionale tramite Git branch) e deployment, garantendo che qualsiasi modifica nei dati o negli algoritmi attiverà automaticamente questo processo. Questo approccio ci aiuta a costruire applicazioni veloci, scalabili e pronte per la produzione.\n","Si prega di notare che si usano molteplici strumenti MLOps in progetti reali per orchestrare, versionare, rilasciare e monitorare applicazioni di machine learning."],"id":"rV5KSudhjCFo"}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}